{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b62b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhij\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding    \n",
    "import faiss\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from Bio import Entrez\n",
    "import time\n",
    "import xmltodict\n",
    "from pathlib import Path\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_correctness, faithfulness, context_recall, AnswerCorrectness\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90260b52",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80688f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_path = r\"E:\\RAG_Models\\BioASQ-training13b\\training13b.json\"\n",
    "abstract_cache = Path(r\".\\Abstracts\")\n",
    "email = \"an80@illinois.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "719b872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_cache.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f96293",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f29cc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_dataset_path,\"r\") as file:\n",
    "    bioasq_json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ca32171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_urls = []\n",
    "questions = []\n",
    "ground_truth = []\n",
    "for data in bioasq_json_data['questions'][:100]:\n",
    "   document_urls.extend(data.get('documents'))\n",
    "   question = data.get(\"body\")\n",
    "   questions.append(question)\n",
    "   ground_truth.append(data.get(\"ideal_answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "566928a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate documents. Original number of documents: 1142\n",
      "Number of documents after filtering: 1136\n"
     ]
    }
   ],
   "source": [
    "print(f'Checking for duplicate documents. Original number of documents: {len(document_urls)}')\n",
    "document_urls = list(set(document_urls))\n",
    "print(f'Number of documents after filtering: {len(document_urls)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "df6a515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 100\n",
      "Number of ground truths: 100\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of questions: {len(questions)}')\n",
    "print(f'Number of ground truths: {len(ground_truth)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5102e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df = pd.DataFrame(columns=['Question','Ground Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "97bf28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df['Question'] = questions\n",
    "bioasq_df['Ground Truth'] = ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5af7f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>[Coding sequence mutations in RET, GDNF, EDNRB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>[The 7 known EGFR ligands  are: epidermal grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>[Yes,  papilin is a secreted protein]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>[Long non coding RNAs appear to be spliced thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>[Receptor activator of nuclear factor κB ligan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1  List signaling molecules (ligands) that intera...   \n",
       "2                   Is the protein Papilin secreted?   \n",
       "3                  Are long non coding RNAs spliced?   \n",
       "4                  Is RANKL secreted from the cells?   \n",
       "\n",
       "                                        Ground Truth  \n",
       "0  [Coding sequence mutations in RET, GDNF, EDNRB...  \n",
       "1  [The 7 known EGFR ligands  are: epidermal grow...  \n",
       "2              [Yes,  papilin is a secreted protein]  \n",
       "3  [Long non coding RNAs appear to be spliced thr...  \n",
       "4  [Receptor activator of nuclear factor κB ligan...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioasq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ccacb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df.to_csv(\"bioasq_ground_truth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0ef86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMID_RE = re.compile(r\"/pubmed/(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22200e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmid_from_url(url: str) -> str:\n",
    "    m = PMID_RE.search(url)\n",
    "    return m.group(1) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e926e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = [pmid_from_url(doc) for doc in document_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c50dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_fetch_pmids(pmids, batch = 200):\n",
    "    \"\"\"Return {pmid: {'title','abstract','year'}}; caches and skips empty abstracts.\"\"\"\n",
    "    out = {}\n",
    "    for i in range(0, len(pmids), batch):\n",
    "        chunk = pmids[i:i + batch]\n",
    "        need = [p for p in chunk if not (abstract_cache / f\"{p}.json\").exists()]\n",
    "        if need:\n",
    "            raw_xml = Entrez.efetch(\n",
    "                db=\"pubmed\",\n",
    "                id=\",\".join(need),\n",
    "                rettype=\"abstract\",\n",
    "                retmode=\"xml\"\n",
    "            ).read()\n",
    "            xml = xmltodict.parse(raw_xml)\n",
    "            for art in xml[\"PubmedArticleSet\"][\"PubmedArticle\"]:\n",
    "                pmid = art[\"MedlineCitation\"][\"PMID\"][\"#text\"]\n",
    "                art_info = art[\"MedlineCitation\"][\"Article\"]\n",
    "                title = art_info.get(\"ArticleTitle\", \"\")\n",
    "\n",
    "                # ---- robust abstract extraction ----\n",
    "                abs_raw = art_info.get(\"Abstract\", {}).get(\"AbstractText\", [])\n",
    "                if isinstance(abs_raw, list):\n",
    "                    parts = [x.get(\"#text\", \"\") if isinstance(x, dict) else str(x) for x in abs_raw]\n",
    "                    abstract = \" \".join(parts).strip()\n",
    "                else:\n",
    "                    abstract = str(abs_raw).strip()\n",
    "\n",
    "                if not abstract:   # skip if empty\n",
    "                    continue\n",
    "\n",
    "                year = art_info[\"Journal\"][\"JournalIssue\"][\"PubDate\"].get(\"Year\", \"Unknown\")\n",
    "\n",
    "                meta = {\"title\": title, \"abstract\": abstract, \"year\": year}\n",
    "                (abstract_cache / f\"{pmid}.json\").write_text(json.dumps(meta))\n",
    "\n",
    "        # load all cached (existing + newly saved)\n",
    "        for pmid in chunk:\n",
    "            fp = abstract_cache / f\"{pmid}.json\"\n",
    "            if fp.exists():\n",
    "                meta = json.loads(fp.read_text())\n",
    "                if meta.get(\"abstract\", \"\").strip():\n",
    "                    out[pmid] = meta\n",
    "        time.sleep(0.4)  # politeness\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4552b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = batch_fetch_pmids(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b8b0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = r\".\\Abstracts\"\n",
    "out_csv = \"pubmed_abstracts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94cb3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = pd.DataFrame(columns=[\"title\", \"abstract\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c12bb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(source_directory):\n",
    "    file_path = os.path.join(source_directory,file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        try:\n",
    "            json_data = json.loads(f.read())\n",
    "            title = json_data.get('title')   \n",
    "            abstract = json_data.get('abstract')\n",
    "            year = json_data.get('year')\n",
    "            abstracts_df.loc[len(abstracts_df)] = [title, abstract, year]     \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a56bbd",
   "metadata": {},
   "source": [
    "### Testing the model - No need to execute previous cells - Start by loading the csv files directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6dd4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_documents(df):\n",
    "    docs = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[\"abstract\"]\n",
    "        metadata = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"year\": row.get(\"year\", \"\"),\n",
    "        }\n",
    "        docs.append(Document(text=text, metadata=metadata))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e797bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = os.path.join(os.getcwd(), out_csv)\n",
    "abstracts_df.to_csv(target_directory, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29add5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df = pd.read_csv('bioasq_ground_truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007a3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = pd.read_csv('pubmed_abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc29e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = abstracts_df.dropna(subset='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4ca77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dataframe_to_documents(abstracts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa429fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = r\"E:\\RAG_Models\"\n",
    "model_name = \"phi-2-orange.Q4_K_M.gguf\"\n",
    "\n",
    "model_path = model_directory+\"\\\\\"+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd31467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 325 tensors from E:\\RAG_Models\\phi-2-orange.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
      "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50295\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 50256\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  195 tensors\n",
      "llama_model_loader: - type q4_K:   81 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.66 GiB (5.14 BPW) \n",
      "load: missing pre-tokenizer type, using: 'default'\n",
      "load:                                             \n",
      "load: ************************************        \n",
      "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
      "load: CONSIDER REGENERATING THE MODEL             \n",
      "load: ************************************        \n",
      "load:                                             \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: special tokens cache size = 944\n",
      "load: token to piece cache size = 0.3151 MB\n",
      "print_info: arch             = phi2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 2048\n",
      "print_info: n_embd           = 2560\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 32\n",
      "print_info: n_rot            = 32\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 80\n",
      "print_info: n_embd_head_v    = 80\n",
      "print_info: n_gqa            = 1\n",
      "print_info: n_embd_k_gqa     = 2560\n",
      "print_info: n_embd_v_gqa     = 2560\n",
      "print_info: f_norm_eps       = 1.0e-05\n",
      "print_info: f_norm_rms_eps   = 0.0e+00\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 10240\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 2048\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 2.78 B\n",
      "print_info: general.name     = Phi2\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 51200\n",
      "print_info: n_merges         = 50000\n",
      "print_info: BOS token        = 50256 '<|endoftext|>'\n",
      "print_info: EOS token        = 50295 '<|im_end|>'\n",
      "print_info: EOT token        = 50295 '<|im_end|>'\n",
      "print_info: UNK token        = 50256 '<|endoftext|>'\n",
      "print_info: PAD token        = 50256 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 50256 '<|endoftext|>'\n",
      "print_info: EOG token        = 50295 '<|im_end|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 244 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:  CPU_AARCH64 model buffer size =   787.50 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  1704.63 MiB\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.28.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.30.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
      ".............................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.20 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   640.00 MiB\n",
      "llama_kv_cache_unified: KV self size  =  640.00 MiB, K (f16):  320.00 MiB, V (f16):  320.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context:        CPU compute buffer size =   167.01 MiB\n",
      "llama_context: graph nodes  = 1289\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.architecture': 'phi2', 'phi2.context_length': '2048', 'general.name': 'Phi2', 'tokenizer.ggml.padding_token_id': '50256', 'phi2.attention.head_count_kv': '32', 'phi2.embedding_length': '2560', 'tokenizer.ggml.add_bos_token': 'false', 'phi2.feed_forward_length': '10240', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '50256', 'phi2.block_count': '32', 'phi2.attention.head_count': '32', 'phi2.attention.layer_norm_epsilon': '0.000010', 'phi2.rope.dimension_count': '32', 'tokenizer.ggml.eos_token_id': '50295', 'general.file_type': '15', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.unknown_token_id': '50256'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCPP(model_path = model_path, temperature = 0.2, max_new_tokens = 256, context_window = 2048, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb569a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e7b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name = \"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25178a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "Settings.node_parser = text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8edf43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = len(Settings.embed_model.get_text_embedding(\"sample text\"))\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(dimensions)\n",
    "faiss_db = FaissVectorStore(faiss_index = faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store = faiss_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa59c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2604634",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit = 600)\n",
    "query_engine = index.as_query_engine(similarity_top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6ec1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine = query_engine,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9754daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = bioasq_df['Question'][:3]\n",
    "sample_gt = bioasq_df['Ground Truth'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca2668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_context(query):\n",
    "    response = chat_engine.chat(query)\n",
    "    chunks = [n.node.get_content() for n in response.source_nodes]\n",
    "    context_str = \"\\n\".join(chunks)\n",
    "    \n",
    "    return pd.Series({\"Response\": response.response, \"Context\": context_str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d06710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = bioasq_df.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ec48217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   34580.35 ms /  1108 tokens (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30203.08 ms /   229 runs   (  131.89 ms per token,     7.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   65189.10 ms /  1337 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =    9036.01 ms /   325 tokens (   27.80 ms per token,    35.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30680.14 ms /   255 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_perf_context_print:       total time =   40062.83 ms /   580 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   42594.90 ms /  1559 tokens (   27.32 ms per token,    36.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35086.97 ms /   255 runs   (  137.60 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   77984.16 ms /  1814 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   14740.61 ms /   606 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   27606.02 ms /   255 runs   (  108.26 ms per token,     9.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   42649.56 ms /   861 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   41958.15 ms /  1554 tokens (   27.00 ms per token,    37.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   31820.70 ms /   255 runs   (  124.79 ms per token,     8.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   74103.08 ms /  1809 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   14529.53 ms /   625 tokens (   23.25 ms per token,    43.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =   26996.20 ms /   255 runs   (  105.87 ms per token,     9.45 tokens per second)\n",
      "llama_perf_context_print:       total time =   41894.83 ms /   880 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   35132.73 ms /  1399 tokens (   25.11 ms per token,    39.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =   31669.45 ms /   255 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   67065.05 ms /  1654 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   16592.38 ms /   614 tokens (   27.02 ms per token,    37.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =   28001.32 ms /   255 runs   (  109.81 ms per token,     9.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   44838.16 ms /   869 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   32119.08 ms /  1166 tokens (   27.55 ms per token,    36.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30740.07 ms /   255 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_perf_context_print:       total time =   63190.81 ms /  1421 tokens\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_2528\\717986775.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[['Response','Context']] = test_df['Question'].apply(lambda row: get_answer_context(row))\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_2528\\717986775.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[['Response','Context']] = test_df['Question'].apply(lambda row: get_answer_context(row))\n"
     ]
    }
   ],
   "source": [
    "test_df[['Response','Context']] = test_df['Question'].apply(lambda row: get_answer_context(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a4a9a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Response</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>[Coding sequence mutations in RET, GDNF, EDNRB...</td>\n",
       "      <td>\\nHirschsprung disease is a multifactorial dis...</td>\n",
       "      <td>Hirschsprung's disease (HSCR) is a fairly freq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>[The 7 known EGFR ligands  are: epidermal grow...</td>\n",
       "      <td>\\nThe signaling molecules that interact with t...</td>\n",
       "      <td>The epidermal growth factor receptor (EGFR) is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>[Yes,  papilin is a secreted protein]</td>\n",
       "      <td>\\nNo, Papilin does not belong to the family of...</td>\n",
       "      <td>A sulfated glycoprotein was isolated from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>[Long non coding RNAs appear to be spliced thr...</td>\n",
       "      <td>\\n\\nNo, long non-coding RNAs (lncRNAs) do not ...</td>\n",
       "      <td>Long non-coding RNAs (lncRNAs) resemble protei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>[Receptor activator of nuclear factor κB ligan...</td>\n",
       "      <td>\\nRANKL (RANK ligand) is a transmembrane prote...</td>\n",
       "      <td>Receptor activator of nuclear factor-kappaB-li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1  List signaling molecules (ligands) that intera...   \n",
       "2                   Is the protein Papilin secreted?   \n",
       "3                  Are long non coding RNAs spliced?   \n",
       "4                  Is RANKL secreted from the cells?   \n",
       "\n",
       "                                        Ground Truth  \\\n",
       "0  [Coding sequence mutations in RET, GDNF, EDNRB...   \n",
       "1  [The 7 known EGFR ligands  are: epidermal grow...   \n",
       "2              [Yes,  papilin is a secreted protein]   \n",
       "3  [Long non coding RNAs appear to be spliced thr...   \n",
       "4  [Receptor activator of nuclear factor κB ligan...   \n",
       "\n",
       "                                            Response  \\\n",
       "0  \\nHirschsprung disease is a multifactorial dis...   \n",
       "1  \\nThe signaling molecules that interact with t...   \n",
       "2  \\nNo, Papilin does not belong to the family of...   \n",
       "3  \\n\\nNo, long non-coding RNAs (lncRNAs) do not ...   \n",
       "4  \\nRANKL (RANK ligand) is a transmembrane prote...   \n",
       "\n",
       "                                             Context  \n",
       "0  Hirschsprung's disease (HSCR) is a fairly freq...  \n",
       "1  The epidermal growth factor receptor (EGFR) is...  \n",
       "2  A sulfated glycoprotein was isolated from the ...  \n",
       "3  Long non-coding RNAs (lncRNAs) resemble protei...  \n",
       "4  Receptor activator of nuclear factor-kappaB-li...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6158c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_responses(response):\n",
    "    response = response.replace(\"\\n\",\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8387145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:,'Response'] = test_df['Response'].apply(lambda row: clean_responses(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8906b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df = test_df.rename(columns={\n",
    "    \"Question\": \"question\",\n",
    "    \"Context\": \"retrieved_contexts\",\n",
    "    \"Response\": \"answer\",\n",
    "    \"Ground Truth\": \"ground_truth\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4878a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df[\"ground_truth\"] = rag_df[\"ground_truth\"].apply(\n",
    "    lambda x: \" \".join(x) if isinstance(x, (list, tuple)) else str(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabe0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df[\"retrieved_contexts\"] = rag_df[\"retrieved_contexts\"].apply(lambda x: [x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "016678f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df.to_csv('BioASQ_Test_Responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49b275fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df = pd.read_csv('BioASQ_Test_Responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38bbf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98d2f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(val):\n",
    "    # if it's already a list, pass through; if it's a str, parse it\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    return ast.literal_eval(val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fb3809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df[\"retrieved_contexts\"] = rag_df[\"retrieved_contexts\"].apply(to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b794110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>[Hirschsprung's disease (HSCR) is a fairly fre...</td>\n",
       "      <td>Hirschsprung disease is a multifactorial disor...</td>\n",
       "      <td>Coding sequence mutations in RET, GDNF, EDNRB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>[The epidermal growth factor receptor (EGFR) i...</td>\n",
       "      <td>The signaling molecules that interact with the...</td>\n",
       "      <td>The 7 known EGFR ligands  are: epidermal growt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>[A sulfated glycoprotein was isolated from the...</td>\n",
       "      <td>No, Papilin does not belong to the family of s...</td>\n",
       "      <td>Yes,  papilin is a secreted protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>[Long non-coding RNAs (lncRNAs) resemble prote...</td>\n",
       "      <td>No, long non-coding RNAs (lncRNAs) do not unde...</td>\n",
       "      <td>Long non coding RNAs appear to be spliced thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>[Receptor activator of nuclear factor-kappaB-l...</td>\n",
       "      <td>RANKL (RANK ligand) is a transmembrane protein...</td>\n",
       "      <td>Receptor activator of nuclear factor κB ligand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1  List signaling molecules (ligands) that intera...   \n",
       "2                   Is the protein Papilin secreted?   \n",
       "3                  Are long non coding RNAs spliced?   \n",
       "4                  Is RANKL secreted from the cells?   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Hirschsprung's disease (HSCR) is a fairly fre...   \n",
       "1  [The epidermal growth factor receptor (EGFR) i...   \n",
       "2  [A sulfated glycoprotein was isolated from the...   \n",
       "3  [Long non-coding RNAs (lncRNAs) resemble prote...   \n",
       "4  [Receptor activator of nuclear factor-kappaB-l...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Hirschsprung disease is a multifactorial disor...   \n",
       "1  The signaling molecules that interact with the...   \n",
       "2  No, Papilin does not belong to the family of s...   \n",
       "3  No, long non-coding RNAs (lncRNAs) do not unde...   \n",
       "4  RANKL (RANK ligand) is a transmembrane protein...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  Coding sequence mutations in RET, GDNF, EDNRB,...  \n",
       "1  The 7 known EGFR ligands  are: epidermal growt...  \n",
       "2                Yes,  papilin is a secreted protein  \n",
       "3  Long non coding RNAs appear to be spliced thro...  \n",
       "4  Receptor activator of nuclear factor κB ligand...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_df[[\"question\", \"retrieved_contexts\", \"answer\", \"ground_truth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c5d60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_ds = Dataset.from_pandas(\n",
    "    rag_df[[\"question\", \"retrieved_contexts\", \"answer\", \"ground_truth\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bc87b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hirschsprung's disease (HSCR) is a fairly frequent cause of intestinal obstruction in children. It is characterized as a sex-linked heterogonous disorder with variable severity and incomplete penetrance giving rise to a variable pattern of inheritance. Although Hirschsprung's disease occurs as an isolated phenotype in at least 70% of cases, it is not infrequently associated with a number of congenital abnormalities and associated syndromes, demonstrating a spectrum of congenital anomalies. Certain of these syndromic phenotypes have been linked to distinct genetic sites, indicating underlying genetic associations of the disease and probable gene-gene interaction, in its pathogenesis. These associations with HSCR include Down's syndrome and other chromosomal anomalies, Waardenburg syndrome and other Dominant sensorineural deafness, the Congenital Central Hypoventilation and Mowat-Wilson and other brain-related syndromes, as well as the MEN2 and other tumour associations. A number of other autosomal recessive syndromes include the Shah-Waardenburg, the Bardet-Biedl and Cartilage-hair hypoplasia, Goldberg-Shprintzen syndromes and other syndromes related to cholesterol and fat metabolism among others. The genetics of Hirschsprung's disease are highly complex with the majority of known genetic sites relating to the main susceptibility pathways (RET an EDNRB). Non-syndromic non-familial, short-segment HSCR appears to represent a non-Mendelian condition with variable expression and sex-dependent penetrance. Syndromic and familial forms, on the other hand, have complex patterns of inheritance and being reported as autosomal dominant, recessive and polygenic patterns of inheritance. The phenotypic variability and incomplete penetrance observed in Hirschsprung's disease could also be explained by the involvement of modifier genes, especially in its syndromic forms. In this review, we look at the chromosomal and Mendelian associations and their underlying signalling pathways, to obtain a better understanding of the pathogenetic mechanisms involved in developing aganglionosis of the distal bowel.\\nHirschsprung disease (HSCR), or congenital intestinal aganglionosis, is a common hereditary disorder causing intestinal obstruction, thereby showing considerable phenotypic variation in conjunction with complex inheritance. Moreover, phenotypic assessment of the disease has been complicated since a subset of the observed mutations is also associated with several additional syndromic anomalies. Coding sequence mutations in e.g. RET, GDNF, EDNRB, EDN3, and SOX10 lead to long-segment (L-HSCR) as well as syndromic HSCR but fail to explain the transmission of the much more common short-segment form (S-HSCR). Furthermore, mutations in the RET gene are responsible for approximately half of the familial and some sporadic cases, strongly suggesting, on the one hand, the importance of non-coding variations and, on the other hand, that additional genes involved in the development of the enteric nervous system still await their discovery. For almost all of the identified HSCR genes incomplete penetrance of the HSCR phenotype has been reported, probably due to modifier loci. Therefore, HSCR has become a model for a complex oligo-/polygenic disorder in which the relationship between different genes creating a non-mendelian inheritance pattern still remains to be elucidated.\\nThe identification of common variants that contribute to the genesis of human inherited disorders remains a significant challenge. Hirschsprung disease (HSCR) is a multifactorial, non-mendelian disorder in which rare high-penetrance coding sequence mutations in the receptor tyrosine kinase RET contribute to risk in combination with mutations at other genes. We have used family-based association studies to identify a disease interval, and integrated this with comparative and functional genomic analysis to prioritize conserved and functional elements within which mutations can be sought. We now show that a common non-coding RET variant within a conserved enhancer-like sequence in intron 1 is significantly associated with HSCR susceptibility and makes a 20-fold greater contribution to risk than rare alleles do. This mutation reduces in vitro enhancer activity markedly, has low penetrance, has different genetic effects in males and females, and explains several features of the complex inheritance pattern of HSCR. Thus, common low-penetrance variants, identified by association studies, can underlie both common and rare diseases.\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_df.loc[0,'retrieved_contexts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "766b0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LlamaIndexLLMWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a533a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LlamaIndexLLMWrapper(Settings.llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53ab9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"\"\"\n",
    "Evaluate the correctness of the answer based on the ground truth. Return a JSON object with 'score' (0.0-1.0) and 'reason'.\n",
    "Examples of valid outputs:\n",
    "{{\"score\": 0.2, \"reason\": \"Explanation...\"}}\n",
    "\n",
    "Question: {question}\n",
    "Ground Truth: {ground_truth}\n",
    "Answer: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea1a500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_correctness = AnswerCorrectness(llm = evaluator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4720b6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_required_columns': {<MetricType.SINGLE_TURN: 'single_turn'>: {'reference',\n",
       "   'response',\n",
       "   'user_input'}},\n",
       " 'name': 'answer_correctness',\n",
       " 'embeddings': HuggingFaceEmbedding(model_name='pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x000001F08E1A9310>, num_workers=None, max_length=100, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None, show_progress_bar=False),\n",
       " 'llm': LlamaIndexLLMWrapper(llm=LlamaCPP(...)),\n",
       " 'output_type': None,\n",
       " 'correctness_prompt': CorrectnessClassifier(instruction=\n",
       " Evaluate the correctness of the answer based on the ground truth. Return a JSON object with 'score' (0.0-1.0) and 'reason'.\n",
       " Examples of valid outputs:\n",
       " {{\"score\": 0.2, \"reason\": \"Explanation...\"}}\n",
       " \n",
       " Question: {question}\n",
       " Ground Truth: {ground_truth}\n",
       " Answer: {answer}\n",
       " , examples=[(QuestionAnswerGroundTruth(question='What powers the sun and what is its primary function?', answer=['The sun is powered by nuclear fission, similar to nuclear reactors on Earth.', 'The primary function of the sun is to provide light to the solar system.'], ground_truth=['The sun is powered by nuclear fusion, where hydrogen atoms fuse to form helium.', \"This fusion process in the sun's core releases a tremendous amount of energy.\", 'The energy from the sun provides heat and light, which are essential for life on Earth.', \"The sun's light plays a critical role in Earth's climate system.\", 'Sunlight helps to drive the weather and ocean currents.']), ClassificationWithReason(TP=[StatementsWithReason(statement='The primary function of the sun is to provide light to the solar system.', reason=\"This statement is somewhat supported by the ground truth mentioning the sun providing light and its roles, though it focuses more broadly on the sun's energy.\")], FP=[StatementsWithReason(statement='The sun is powered by nuclear fission, similar to nuclear reactors on Earth.', reason='This statement is incorrect and contradicts the ground truth which states that the sun is powered by nuclear fusion.')], FN=[StatementsWithReason(statement='The sun is powered by nuclear fusion, where hydrogen atoms fuse to form helium.', reason='This accurate description of the sun’s power source is not included in the answer.'), StatementsWithReason(statement=\"This fusion process in the sun's core releases a tremendous amount of energy.\", reason='This process and its significance are not mentioned in the answer.'), StatementsWithReason(statement='The energy from the sun provides heat and light, which are essential for life on Earth.', reason='The answer only mentions light, omitting the essential aspects of heat and its necessity for life, which the ground truth covers.'), StatementsWithReason(statement=\"The sun's light plays a critical role in Earth's climate system.\", reason=\"This broader impact of the sun’s light on Earth's climate system is not addressed in the answer.\"), StatementsWithReason(statement='Sunlight helps to drive the weather and ocean currents.', reason='The effect of sunlight on weather patterns and ocean currents is omitted in the answer.')])), (QuestionAnswerGroundTruth(question='What is the boiling point of water?', answer=['The boiling point of water is 100 degrees Celsius at sea level'], ground_truth=['The boiling point of water is 100 degrees Celsius (212 degrees Fahrenheit) at sea level.', 'The boiling point of water can change with altitude.']), ClassificationWithReason(TP=[StatementsWithReason(statement='The boiling point of water is 100 degrees Celsius at sea level', reason='This statement is directly supported by the ground truth which specifies the boiling point of water as 100 degrees Celsius at sea level.')], FP=[], FN=[StatementsWithReason(statement='The boiling point of water can change with altitude.', reason='This additional information about how the boiling point of water can vary with altitude is not mentioned in the answer.')]))], language=english),\n",
       " 'statement_generator_prompt': StatementGeneratorPrompt(instruction=Given a question and an answer, analyze the complexity of each sentence in the answer. Break down each sentence into one or more fully understandable statements. Ensure that no pronouns are used in any statement. Format the outputs in JSON., examples=[(StatementGeneratorInput(question='Who was Albert Einstein and what is he best known for?', answer='He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.'), StatementGeneratorOutput(statements=['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.', 'Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']))], language=english),\n",
       " 'weights': [0.75, 0.25],\n",
       " 'beta': 1.0,\n",
       " 'answer_similarity': None,\n",
       " 'max_retries': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_correctness.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2055d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_correctness.correctness_prompt.instruction = custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a2a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_correctness.embeddings = Settings.embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d60c131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   22485.76 ms /   626 tokens (   35.92 ms per token,    27.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30093.42 ms /   255 runs   (  118.01 ms per token,     8.47 tokens per second)\n",
      "llama_perf_context_print:       total time =   53231.61 ms /   881 tokens\n",
      "Llama.generate: 396 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =    3064.49 ms /   107 tokens (   28.64 ms per token,    34.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =   53704.47 ms /   255 runs   (  210.61 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:       total time =   57776.24 ms /   362 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   95514.56 ms /  1671 tokens (   57.16 ms per token,    17.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =   60740.16 ms /   255 runs   (  238.20 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:       total time =  157809.37 ms /  1926 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   19218.43 ms /   660 tokens (   29.12 ms per token,    34.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35750.34 ms /   255 runs   (  140.20 ms per token,     7.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   55750.78 ms /   915 tokens\n",
      "Llama.generate: 396 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2996.78 ms /    85 tokens (   35.26 ms per token,    28.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30388.44 ms /   255 runs   (  119.17 ms per token,     8.39 tokens per second)\n",
      "llama_perf_context_print:       total time =   33700.14 ms /   340 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   50127.16 ms /  1680 tokens (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =   34845.63 ms /   255 runs   (  136.65 ms per token,     7.32 tokens per second)\n",
      "llama_perf_context_print:       total time =   85329.78 ms /  1935 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   20100.04 ms /   642 tokens (   31.31 ms per token,    31.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =   47113.39 ms /   255 runs   (  184.76 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:       total time =   67840.40 ms /   897 tokens\n",
      "Llama.generate: 388 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1312.67 ms /    19 tokens (   69.09 ms per token,    14.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =   44293.32 ms /   255 runs   (  173.70 ms per token,     5.76 tokens per second)\n",
      "llama_perf_context_print:       total time =   46066.21 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   54014.41 ms /  1599 tokens (   33.78 ms per token,    29.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   50431.83 ms /   255 runs   (  197.77 ms per token,     5.06 tokens per second)\n",
      "llama_perf_context_print:       total time =  105014.92 ms /  1854 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   25317.46 ms /   646 tokens (   39.19 ms per token,    25.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =   68375.11 ms /   255 runs   (  268.14 ms per token,     3.73 tokens per second)\n",
      "llama_perf_context_print:       total time =   94377.19 ms /   901 tokens\n",
      "Llama.generate: 388 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1094.24 ms /    26 tokens (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =   36083.68 ms /   255 runs   (  141.50 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   37525.16 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   44971.83 ms /  1470 tokens (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =   42809.40 ms /   255 runs   (  167.88 ms per token,     5.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   88201.11 ms /  1725 tokens\n",
      "Exception raised in Job[3]: AttributeError('HuggingFaceEmbedding' object has no attribute 'embed_text')\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   19125.34 ms /   649 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =   32542.58 ms /   255 runs   (  127.62 ms per token,     7.84 tokens per second)\n",
      "llama_perf_context_print:       total time =   52109.02 ms /   904 tokens\n",
      "Llama.generate: 389 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1277.62 ms /    36 tokens (   35.49 ms per token,    28.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =   28241.62 ms /   255 runs   (  110.75 ms per token,     9.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   29869.68 ms /   291 tokens\n",
      "llama_perf_context_print:        load time =   22496.49 ms\n",
      "llama_perf_context_print: prompt eval time =   51969.89 ms /  1551 tokens (   33.51 ms per token,    29.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   44559.45 ms /   255 runs   (  174.74 ms per token,     5.72 tokens per second)\n",
      "llama_perf_context_print:       total time =   96995.74 ms /  1806 tokens\n",
      "Evaluating:  20%|██        | 1/5 [17:49<1:11:18, 1069.56s/it]Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 5/5 [17:49<00:00, 213.92s/it]   \n"
     ]
    }
   ],
   "source": [
    "result = evaluate(rag_ds,metrics=[answer_correctness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "225bc339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_correctness': nan}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a1adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
