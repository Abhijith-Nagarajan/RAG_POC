{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "48b62b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding    \n",
    "import faiss\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from Bio import Entrez\n",
    "import time\n",
    "import xmltodict\n",
    "from pathlib import Path\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_correctness, faithfulness, context_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33e1a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80688f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_path = r\"E:\\RAG_Models\\BioASQ-training13b\\training13b.json\"\n",
    "abstract_cache = Path(r\".\\Abstracts\")\n",
    "email = \"an80@illinois.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "719b872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_cache.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f96293",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f29cc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_dataset_path,\"r\") as file:\n",
    "    bioasq_json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ca32171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_urls = []\n",
    "questions = []\n",
    "ground_truth = []\n",
    "for data in bioasq_json_data['questions'][:100]:\n",
    "   document_urls.extend(data.get('documents'))\n",
    "   question = data.get(\"body\")\n",
    "   questions.append(question)\n",
    "   ground_truth.append(data.get(\"ideal_answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "566928a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate documents. Original number of documents: 1142\n",
      "Number of documents after filtering: 1136\n"
     ]
    }
   ],
   "source": [
    "print(f'Checking for duplicate documents. Original number of documents: {len(document_urls)}')\n",
    "document_urls = list(set(document_urls))\n",
    "print(f'Number of documents after filtering: {len(document_urls)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "df6a515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 100\n",
      "Number of ground truths: 100\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of questions: {len(questions)}')\n",
    "print(f'Number of ground truths: {len(ground_truth)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5102e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df = pd.DataFrame(columns=['Question','Ground Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "97bf28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df['Question'] = questions\n",
    "bioasq_df['Ground Truth'] = ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5af7f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>[Coding sequence mutations in RET, GDNF, EDNRB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>[The 7 known EGFR ligands  are: epidermal grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>[Yes,  papilin is a secreted protein]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>[Long non coding RNAs appear to be spliced thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>[Receptor activator of nuclear factor κB ligan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1  List signaling molecules (ligands) that intera...   \n",
       "2                   Is the protein Papilin secreted?   \n",
       "3                  Are long non coding RNAs spliced?   \n",
       "4                  Is RANKL secreted from the cells?   \n",
       "\n",
       "                                        Ground Truth  \n",
       "0  [Coding sequence mutations in RET, GDNF, EDNRB...  \n",
       "1  [The 7 known EGFR ligands  are: epidermal grow...  \n",
       "2              [Yes,  papilin is a secreted protein]  \n",
       "3  [Long non coding RNAs appear to be spliced thr...  \n",
       "4  [Receptor activator of nuclear factor κB ligan...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioasq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ccacb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_df.to_csv(\"bioasq_ground_truth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0ef86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMID_RE = re.compile(r\"/pubmed/(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22200e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmid_from_url(url: str) -> str:\n",
    "    m = PMID_RE.search(url)\n",
    "    return m.group(1) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e926e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = [pmid_from_url(doc) for doc in document_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c50dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_fetch_pmids(pmids, batch = 200):\n",
    "    \"\"\"Return {pmid: {'title','abstract','year'}}; caches and skips empty abstracts.\"\"\"\n",
    "    out = {}\n",
    "    for i in range(0, len(pmids), batch):\n",
    "        chunk = pmids[i:i + batch]\n",
    "        need = [p for p in chunk if not (abstract_cache / f\"{p}.json\").exists()]\n",
    "        if need:\n",
    "            raw_xml = Entrez.efetch(\n",
    "                db=\"pubmed\",\n",
    "                id=\",\".join(need),\n",
    "                rettype=\"abstract\",\n",
    "                retmode=\"xml\"\n",
    "            ).read()\n",
    "            xml = xmltodict.parse(raw_xml)\n",
    "            for art in xml[\"PubmedArticleSet\"][\"PubmedArticle\"]:\n",
    "                pmid = art[\"MedlineCitation\"][\"PMID\"][\"#text\"]\n",
    "                art_info = art[\"MedlineCitation\"][\"Article\"]\n",
    "                title = art_info.get(\"ArticleTitle\", \"\")\n",
    "\n",
    "                # ---- robust abstract extraction ----\n",
    "                abs_raw = art_info.get(\"Abstract\", {}).get(\"AbstractText\", [])\n",
    "                if isinstance(abs_raw, list):\n",
    "                    parts = [x.get(\"#text\", \"\") if isinstance(x, dict) else str(x) for x in abs_raw]\n",
    "                    abstract = \" \".join(parts).strip()\n",
    "                else:\n",
    "                    abstract = str(abs_raw).strip()\n",
    "\n",
    "                if not abstract:   # skip if empty\n",
    "                    continue\n",
    "\n",
    "                year = art_info[\"Journal\"][\"JournalIssue\"][\"PubDate\"].get(\"Year\", \"Unknown\")\n",
    "\n",
    "                meta = {\"title\": title, \"abstract\": abstract, \"year\": year}\n",
    "                (abstract_cache / f\"{pmid}.json\").write_text(json.dumps(meta))\n",
    "\n",
    "        # load all cached (existing + newly saved)\n",
    "        for pmid in chunk:\n",
    "            fp = abstract_cache / f\"{pmid}.json\"\n",
    "            if fp.exists():\n",
    "                meta = json.loads(fp.read_text())\n",
    "                if meta.get(\"abstract\", \"\").strip():\n",
    "                    out[pmid] = meta\n",
    "        time.sleep(0.4)  # politeness\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4552b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = batch_fetch_pmids(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b8b0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = r\".\\Abstracts\"\n",
    "out_csv = \"pubmed_abstracts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94cb3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df = pd.DataFrame(columns=[\"title\", \"abstract\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c12bb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(source_directory):\n",
    "    file_path = os.path.join(source_directory,file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        try:\n",
    "            json_data = json.loads(f.read())\n",
    "            title = json_data.get('title')   \n",
    "            abstract = json_data.get('abstract')\n",
    "            year = json_data.get('year')\n",
    "            abstracts_df.loc[len(abstracts_df)] = [title, abstract, year]     \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6dd4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_documents(df):\n",
    "    docs = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[\"abstract\"]\n",
    "        metadata = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"year\": row.get(\"year\", \"\"),\n",
    "        }\n",
    "        docs.append(Document(text=text, metadata=metadata))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e797bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = os.path.join(os.getcwd(), out_csv)\n",
    "abstracts_df.to_csv(target_directory, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa4ca77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dataframe_to_documents(abstracts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fa429fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = r\"E:\\RAG_Models\"\n",
    "model_name = \"phi-2-orange.Q4_K_M.gguf\"\n",
    "\n",
    "model_path = model_directory+\"\\\\\"+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fd31467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 325 tensors from E:\\RAG_Models\\phi-2-orange.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
      "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
      "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50295\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 50256\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  195 tensors\n",
      "llama_model_loader: - type q4_K:   81 tensors\n",
      "llama_model_loader: - type q5_K:   32 tensors\n",
      "llama_model_loader: - type q6_K:   17 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.66 GiB (5.14 BPW) \n",
      "load: missing pre-tokenizer type, using: 'default'\n",
      "load:                                             \n",
      "load: ************************************        \n",
      "load: GENERATION QUALITY WILL BE DEGRADED!        \n",
      "load: CONSIDER REGENERATING THE MODEL             \n",
      "load: ************************************        \n",
      "load:                                             \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: special tokens cache size = 944\n",
      "load: token to piece cache size = 0.3151 MB\n",
      "print_info: arch             = phi2\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 2048\n",
      "print_info: n_embd           = 2560\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 32\n",
      "print_info: n_rot            = 32\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 80\n",
      "print_info: n_embd_head_v    = 80\n",
      "print_info: n_gqa            = 1\n",
      "print_info: n_embd_k_gqa     = 2560\n",
      "print_info: n_embd_v_gqa     = 2560\n",
      "print_info: f_norm_eps       = 1.0e-05\n",
      "print_info: f_norm_rms_eps   = 0.0e+00\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 10240\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 2048\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 2.78 B\n",
      "print_info: general.name     = Phi2\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 51200\n",
      "print_info: n_merges         = 50000\n",
      "print_info: BOS token        = 50256 '<|endoftext|>'\n",
      "print_info: EOS token        = 50295 '<|im_end|>'\n",
      "print_info: EOT token        = 50295 '<|im_end|>'\n",
      "print_info: UNK token        = 50256 '<|endoftext|>'\n",
      "print_info: PAD token        = 50256 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 50256 '<|endoftext|>'\n",
      "print_info: EOG token        = 50295 '<|im_end|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 244 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:  CPU_AARCH64 model buffer size =   787.50 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  1704.63 MiB\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.28.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.30.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
      ".............................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.20 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   640.00 MiB\n",
      "llama_kv_cache_unified: KV self size  =  640.00 MiB, K (f16):  320.00 MiB, V (f16):  320.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context:        CPU compute buffer size =   167.01 MiB\n",
      "llama_context: graph nodes  = 1289\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.architecture': 'phi2', 'phi2.context_length': '2048', 'general.name': 'Phi2', 'tokenizer.ggml.padding_token_id': '50256', 'phi2.attention.head_count_kv': '32', 'phi2.embedding_length': '2560', 'tokenizer.ggml.add_bos_token': 'false', 'phi2.feed_forward_length': '10240', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '50256', 'phi2.block_count': '32', 'phi2.attention.head_count': '32', 'phi2.attention.layer_norm_epsilon': '0.000010', 'phi2.rope.dimension_count': '32', 'tokenizer.ggml.eos_token_id': '50295', 'general.file_type': '15', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.unknown_token_id': '50256'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCPP(model_path = model_path, temperature = 0.2, max_new_tokens = 256, context_window = 2048, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb569a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42e7b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name = \"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25178a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "Settings.node_parser = text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8edf43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = len(Settings.embed_model.get_text_embedding(\"sample text\"))\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(dimensions)\n",
    "faiss_db = FaissVectorStore(faiss_index = faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store = faiss_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0aa59c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2604634",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit = 600)\n",
    "query_engine = index.as_query_engine(similarity_top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7c6ec1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine = query_engine,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b9754daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = bioasq_df['Question'][:3]\n",
    "sample_gt = bioasq_df['Ground Truth'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eca2668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_context(query):\n",
    "    response = chat_engine.chat(query)\n",
    "    chunks = [n.node.get_content() for n in response.source_nodes]\n",
    "    context_str = \"\\n\".join(chunks)\n",
    "    \n",
    "    return pd.Series({\"Response\": response.response, \"Context\": context_str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d06710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = bioasq_df.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ec48217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   34580.35 ms /  1108 tokens (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30203.08 ms /   229 runs   (  131.89 ms per token,     7.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   65189.10 ms /  1337 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =    9036.01 ms /   325 tokens (   27.80 ms per token,    35.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30680.14 ms /   255 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_perf_context_print:       total time =   40062.83 ms /   580 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   42594.90 ms /  1559 tokens (   27.32 ms per token,    36.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35086.97 ms /   255 runs   (  137.60 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   77984.16 ms /  1814 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   14740.61 ms /   606 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   27606.02 ms /   255 runs   (  108.26 ms per token,     9.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   42649.56 ms /   861 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   41958.15 ms /  1554 tokens (   27.00 ms per token,    37.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   31820.70 ms /   255 runs   (  124.79 ms per token,     8.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   74103.08 ms /  1809 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   14529.53 ms /   625 tokens (   23.25 ms per token,    43.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =   26996.20 ms /   255 runs   (  105.87 ms per token,     9.45 tokens per second)\n",
      "llama_perf_context_print:       total time =   41894.83 ms /   880 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   35132.73 ms /  1399 tokens (   25.11 ms per token,    39.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =   31669.45 ms /   255 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   67065.05 ms /  1654 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   16592.38 ms /   614 tokens (   27.02 ms per token,    37.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =   28001.32 ms /   255 runs   (  109.81 ms per token,     9.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   44838.16 ms /   869 tokens\n",
      "llama_perf_context_print:        load time =   34594.90 ms\n",
      "llama_perf_context_print: prompt eval time =   32119.08 ms /  1166 tokens (   27.55 ms per token,    36.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =   30740.07 ms /   255 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_perf_context_print:       total time =   63190.81 ms /  1421 tokens\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_2528\\717986775.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[['Response','Context']] = test_df['Question'].apply(lambda row: get_answer_context(row))\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_2528\\717986775.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[['Response','Context']] = test_df['Question'].apply(lambda row: get_answer_context(row))\n"
     ]
    }
   ],
   "source": [
    "test_df[['Response','Context']] = test_df['Question'].apply(lambda row: get_answer_context(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a4a9a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Response</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>[Coding sequence mutations in RET, GDNF, EDNRB...</td>\n",
       "      <td>\\nHirschsprung disease is a multifactorial dis...</td>\n",
       "      <td>Hirschsprung's disease (HSCR) is a fairly freq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>[The 7 known EGFR ligands  are: epidermal grow...</td>\n",
       "      <td>\\nThe signaling molecules that interact with t...</td>\n",
       "      <td>The epidermal growth factor receptor (EGFR) is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>[Yes,  papilin is a secreted protein]</td>\n",
       "      <td>\\nNo, Papilin does not belong to the family of...</td>\n",
       "      <td>A sulfated glycoprotein was isolated from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>[Long non coding RNAs appear to be spliced thr...</td>\n",
       "      <td>\\n\\nNo, long non-coding RNAs (lncRNAs) do not ...</td>\n",
       "      <td>Long non-coding RNAs (lncRNAs) resemble protei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>[Receptor activator of nuclear factor κB ligan...</td>\n",
       "      <td>\\nRANKL (RANK ligand) is a transmembrane prote...</td>\n",
       "      <td>Receptor activator of nuclear factor-kappaB-li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1  List signaling molecules (ligands) that intera...   \n",
       "2                   Is the protein Papilin secreted?   \n",
       "3                  Are long non coding RNAs spliced?   \n",
       "4                  Is RANKL secreted from the cells?   \n",
       "\n",
       "                                        Ground Truth  \\\n",
       "0  [Coding sequence mutations in RET, GDNF, EDNRB...   \n",
       "1  [The 7 known EGFR ligands  are: epidermal grow...   \n",
       "2              [Yes,  papilin is a secreted protein]   \n",
       "3  [Long non coding RNAs appear to be spliced thr...   \n",
       "4  [Receptor activator of nuclear factor κB ligan...   \n",
       "\n",
       "                                            Response  \\\n",
       "0  \\nHirschsprung disease is a multifactorial dis...   \n",
       "1  \\nThe signaling molecules that interact with t...   \n",
       "2  \\nNo, Papilin does not belong to the family of...   \n",
       "3  \\n\\nNo, long non-coding RNAs (lncRNAs) do not ...   \n",
       "4  \\nRANKL (RANK ligand) is a transmembrane prote...   \n",
       "\n",
       "                                             Context  \n",
       "0  Hirschsprung's disease (HSCR) is a fairly freq...  \n",
       "1  The epidermal growth factor receptor (EGFR) is...  \n",
       "2  A sulfated glycoprotein was isolated from the ...  \n",
       "3  Long non-coding RNAs (lncRNAs) resemble protei...  \n",
       "4  Receptor activator of nuclear factor-kappaB-li...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6158c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_responses(response):\n",
    "    response = response.replace(\"\\n\",\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8387145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:,'Response'] = test_df['Response'].apply(lambda row: clean_responses(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df = test_df.rename(columns={\n",
    "    \"Question\": \"question\",\n",
    "    \"Context\": \"retrieved_contexts\",\n",
    "    \"Response\": \"answer\",\n",
    "    \"Ground Truth\": \"ground_truth\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4878a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_df[\"ground_truth\"] = rag_df[\"ground_truth\"].apply(\n",
    "    lambda x: \" \".join(x) if isinstance(x, (list, tuple)) else str(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_ds = Dataset.from_pandas(\n",
    "    rag_df[[\"question\", \"retrieved_contexts\", \"answer\", \"ground_truth\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b794110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>Hirschsprung's disease (HSCR) is a fairly freq...</td>\n",
       "      <td>Hirschsprung disease is a multifactorial disor...</td>\n",
       "      <td>Coding sequence mutations in RET, GDNF, EDNRB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>The epidermal growth factor receptor (EGFR) is...</td>\n",
       "      <td>The signaling molecules that interact with the...</td>\n",
       "      <td>The 7 known EGFR ligands  are: epidermal growt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>A sulfated glycoprotein was isolated from the ...</td>\n",
       "      <td>No, Papilin does not belong to the family of s...</td>\n",
       "      <td>Yes,  papilin is a secreted protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>Long non-coding RNAs (lncRNAs) resemble protei...</td>\n",
       "      <td>No, long non-coding RNAs (lncRNAs) do not unde...</td>\n",
       "      <td>Long non coding RNAs appear to be spliced thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>Receptor activator of nuclear factor-kappaB-li...</td>\n",
       "      <td>RANKL (RANK ligand) is a transmembrane protein...</td>\n",
       "      <td>Receptor activator of nuclear factor κB ligand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1  List signaling molecules (ligands) that intera...   \n",
       "2                   Is the protein Papilin secreted?   \n",
       "3                  Are long non coding RNAs spliced?   \n",
       "4                  Is RANKL secreted from the cells?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Hirschsprung's disease (HSCR) is a fairly freq...   \n",
       "1  The epidermal growth factor receptor (EGFR) is...   \n",
       "2  A sulfated glycoprotein was isolated from the ...   \n",
       "3  Long non-coding RNAs (lncRNAs) resemble protei...   \n",
       "4  Receptor activator of nuclear factor-kappaB-li...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Hirschsprung disease is a multifactorial disor...   \n",
       "1  The signaling molecules that interact with the...   \n",
       "2  No, Papilin does not belong to the family of s...   \n",
       "3  No, long non-coding RNAs (lncRNAs) do not unde...   \n",
       "4  RANKL (RANK ligand) is a transmembrane protein...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  Coding sequence mutations in RET, GDNF, EDNRB,...  \n",
       "1  The 7 known EGFR ligands  are: epidermal growt...  \n",
       "2                Yes,  papilin is a secreted protein  \n",
       "3  Long non coding RNAs appear to be spliced thro...  \n",
       "4  Receptor activator of nuclear factor κB ligand...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_df[[\"question\", \"retrieved_contexts\", \"answer\", \"ground_truth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d708ca83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The metric [faithfulness] that is used requires the following additional columns ['retrieved_contexts'] to be present in the dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[166]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m report = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrag_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43manswer_correctness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_recall\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhij\\miniconda3\\envs\\RAG\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhij\\miniconda3\\envs\\RAG\\Lib\\site-packages\\ragas\\evaluation.py:176\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    173\u001b[39m     dataset = EvaluationDataset.from_list(dataset.to_list())\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, EvaluationDataset):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[43mvalidate_required_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m     validate_supported_metrics(dataset, metrics)\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# set the llm and embeddings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abhij\\miniconda3\\envs\\RAG\\Lib\\site-packages\\ragas\\validation.py:63\u001b[39m, in \u001b[36mvalidate_required_columns\u001b[39m\u001b[34m(ds, metrics)\u001b[39m\n\u001b[32m     61\u001b[39m available_columns = \u001b[38;5;28mset\u001b[39m(ds.features())\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m required_columns.issubset(available_columns):\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     64\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe metric [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] that is used requires the following \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33madditional columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(required_columns\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mavailable_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     66\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto be present in the dataset.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The metric [faithfulness] that is used requires the following additional columns ['retrieved_contexts'] to be present in the dataset."
     ]
    }
   ],
   "source": [
    "report = evaluate(\n",
    "    rag_ds,\n",
    "    metrics=[answer_correctness, faithfulness, context_recall]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cb3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
