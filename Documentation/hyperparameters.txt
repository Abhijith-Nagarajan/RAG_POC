By default, LlamaIndex uses default parameters such as:
1) Embedding model - openai/text-embedding-ada-002
2) Chunking - Chunk size  = 1024 characters and chunk overlap = 20 characters
3) Memory - Uses in-memory storage
4) Number of chunks retrieved - 4 nodes per query
---------------------------------------------------------------------------------------------------------------------------------------------------------------
Modifying these parameters:

1) Chunking - ServiceContext and SentenceSplitter

text_splitter = SentenceSplitter(chunk_size = 100, chunk_overlap = 5)
service_context = ServiceContext.from_defaults(node_parser = text_splitter,)
---------------------------------------------------------------------------------------------------------------------------------------------------------------
2) Embedding model - Using HuggingFaceEmbedding

embed_model = HuggingFaceEmbedding(model='model_name')
service_context = ServiceContext.from_defaults(node_parser = text_splitter,embed_model = embed_model)
---------------------------------------------------------------------------------------------------------------------------------------------------------------
3) Number of chunks retrieved

index = VectorSpaceIndex.from_documents(documents, service_context = service_context) 
query_engine = index.as_query_engine(similarity_top_k = 5)
---------------------------------------------------------------------------------------------------------------------------------------------------------------
4) Memory - Can use FAISS for example - Using StorageContext and FaissVectorStore

faiss_store = FaissVectorStore()
storage_context = StorageContext.from_defaults(vector_store = faiss_store)

index = VectorSpaceIndex.from_documents(documents, service_context = service_context, storage_context = storage_context) 
query_engine = index.as_query_engine(similarity_top_k = 5)
---------------------------------------------------------------------------------------------------------------------------------------------------------------



